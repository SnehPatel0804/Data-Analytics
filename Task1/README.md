ğŸ“‹ Project Overview
This project focuses on performing data analysis on a large customer dataset using PySpark to demonstrate the capability of processing big data efficiently.
The main goal was to derive meaningful insights from the dataset, analyze customer behaviors, and demonstrate scalability using big data tools.

ğŸ› ï¸ Technologies Used
Python 

Apache PySpark  (for big data processing and scalable analytics)

Pandas (for small data handling after initial analysis)

Matplotlib & Seaborn ğŸ“Š (for data visualization)

Google Colab (for cloud-based development and testing)

ğŸ“ˆ Steps and Work Done
Data Loading
Loaded a large CSV file into PySpark DataFrame with automatic schema inference.

Data Exploration

Printed schema, counted records, checked for nulls.

Summarized numerical statistics.

Extracted column names and their types.

Descriptive Analysis

Top 5 customers by Balance and Estimated Salary.

Average Credit Score and Average Salary.

Geographical Distribution of customers (Spain, France, Germany).

Gender Distribution among customers.

Churn Rate Analysis (Exited vs. Active customers).

Advanced Insights

Correlation Analysis between numerical features.

Geography vs Churn analysis.

Gender vs Churn behavior study.

Bucketization:

Age groups

Salary groups

Retention Strategy Insights for high-value customers.

Visualization

Histograms, Countplots, Scatterplots.

Churn vs Geography, Churn vs Gender.

Distribution of Salaries, Age, and Balances.

ğŸ”¥ Key Takeaways
PySpark can easily handle large datasets and perform complex operations efficiently.

Found that certain geographies and genders had higher churn rates.

Identified high-value customers who were more likely to churn, providing insights for retention strategies.

Created easy-to-understand visualizations to support the derived insights.